"""Describe the Haddock3 ontology used for communicating between modules."""

import datetime
import itertools
import os
import re
from enum import Enum
from functools import partial
from os import linesep
from os.path import getmtime
from pathlib import Path

import jsonpickle

from haddock.core.defaults import MODULE_IO_FILE
from haddock.core.typing import (
    Any,
    FilePath,
    Iterable,
    List,
    Optional,
    TypeVar,
    Union,
    )
from haddock.libs.libpdb import split_ensemble


NaN = float("nan")


class Format(Enum):
    """Input and Output possible formats."""

    PDB = "pdb"
    PDB_ENSEMBLE = "pdb"
    CNS_INPUT = "inp"
    CNS_OUTPUT = "out"
    TOPOLOGY = "psf"
    MATRIX = "matrix"

    def __str__(self) -> str:
        return str(self.value)


class Persistent:
    """Any persistent file generated by this framework."""

    def __init__(
            self,
            file_name: FilePath,
            file_type: Format,
            path: FilePath = ".",
            md5: Optional[str] = None,
            restr_fname: Optional[FilePath] = None,
            ) -> None:
        self.created = datetime.datetime.now().isoformat(" ", "seconds")
        self.file_name = Path(file_name).name
        self.file_type = file_type
        self.path = str(Path(path).resolve())
        self.full_name = str(Path(path, self.file_name))
        self.rel_path = Path("..", Path(self.path).name, file_name)
        self.md5 = md5
        self.restr_fname = restr_fname

    def __repr__(self) -> str:
        rep = (
            f"[{self.file_type}|{self.created}] "
            f"{Path(self.path) / self.file_name}"
            )
        return rep

    def is_present(self) -> bool:
        """Check if the persisent file exists on disk."""
        return self.rel_path.resolve().exists()


class PDBFile(Persistent):
    """Represent a PDB file."""

    def __init__(
            self,
            file_name: Union[Path, str],
            topology: Optional[Any] = None,
            path: Union[Path, str] = ".",
            score: float = NaN,
            md5: Optional[str] = None,
            restr_fname: Optional[Union[Path, str]] = None,
            unw_energies: Optional[dict[str, float]] = None,
            ) -> None:
        super().__init__(file_name, Format.PDB, path, md5, restr_fname)

        self.topology = topology
        self.score = score
        self.ori_name: Optional[str] = None
        self.clt_id: Union[str, int, None] = None
        self.clt_rank: Optional[int] = None
        self.clt_model_rank: Optional[int] = None
        self.len = score
        self.unw_energies = unw_energies
        self.seed = None

    def __lt__(self, other: "PDBFile") -> bool:
        return self.score < other.score

    def __gt__(self, other: "PDBFile") -> bool:
        return self.score > other.score

    def __eq__(self, other: "PDBFile") -> bool:  # type: ignore
        return self.score == other.score

    def __hash__(self) -> int:
        return id(self)


class RMSDFile(Persistent):
    """Represents a RMSD matrix file."""

    def __init__(
            self,
            file_name: FilePath,
            npairs: int,
            path: FilePath = ".",
            ) -> None:
        super().__init__(file_name, Format.MATRIX, path)
        self.npairs = npairs

    def __hash__(self) -> int:
        return id(self)


class TopologyFile(Persistent):
    """Represent a CNS-generated topology file."""

    def __init__(self, file_name: FilePath, path: FilePath = ".") -> None:
        super().__init__(file_name, Format.TOPOLOGY, path)


class ModuleIO:
    """Intercommunicating modules and exchange input/output information."""

    def __init__(self) -> None:
        self.input: List[Any] = []
        self.output: List[Any] = []

    def add(self, persistent, mode="i"):
        """Add a given filename as input or output."""
        if mode == "i":
            if isinstance(persistent, list):
                self.input.extend(persistent)
            else:
                self.input.append(persistent)
        else:
            if isinstance(persistent, list):
                self.output.extend(persistent)
            else:
                self.output.append(persistent)

    def save(
            self,
            path: FilePath = ".",
            filename: FilePath = MODULE_IO_FILE,
            ) -> Path:
        """Save Input/Output needed files by this module to disk."""
        fpath = Path(path, filename)
        with open(fpath, "w") as output_handler:
            to_save = {"input": self.input, "output": self.output}
            jsonpickle.set_encoder_options("json", sort_keys=True, indent=4)
            output_handler.write(jsonpickle.encode(to_save))  # type: ignore
        return fpath

    def load(self, filename: FilePath) -> None:
        """Load the content of a given IO filename."""
        if Path(filename).is_file():
            with open(filename) as json_file:
                content = jsonpickle.decode(json_file.read())
                self.input = content["input"]  # type: ignore
                self.output = content["output"]  # type: ignore

    def retrieve_models(
            self, crossdock: bool = False, individualize: bool = False
            ) -> list[Union[PDBFile, list[PDBFile]]]:
        """Retrieve the PDBobjects to be used in the module."""
        # Get the models generated in previous step
        model_list: list[PDBFile] = []
        input_dic: dict[int, list[PDBFile]] = {}

        for i, element in enumerate(self.output):
            # Make molecules from elements
            molecule = Molecule(element)
            if isinstance(molecule.pdb_files, dict):
                position_list: list[PDBFile] = input_dic.setdefault(i, [])
                for key in element:
                    position_list.append(element[key])  # type: ignore
            elif molecule.pdb_files.file_type == Format.PDB:  # type: ignore
                model_list.append(element)  # type: ignore

        if input_dic and not crossdock and not individualize:
            # check if all ensembles contain the same number of models
            sub_lists = iter(input_dic.values())
            _len = len(next(sub_lists))
            if not all(len(sub) == _len for sub in sub_lists):
                _msg = (
                    "Different number of models in molecules,"
                    " cannot prepare pairwise complexes."
                    )
                raise Exception(_msg)
            # prepare pairwise combinations
            model_list = [values for values in zip(*input_dic.values())]  # type: ignore
        elif input_dic and crossdock and not individualize:
            model_list = [values for values in itertools.product(*input_dic.values())]  # type: ignore
        elif input_dic and individualize:
            model_list = list(itertools.chain(*input_dic.values()))

        return model_list  # type: ignore

    def check_faulty(self) -> float:
        """Check how many of the output exists."""
        total = 0.0
        present = 0.0
        for element in self.output:
            if isinstance(element, dict):
                total += len(element)
                present += sum(j.is_present() for j in element.values())
            else:
                total += 1
                if element.is_present():
                    present += 1

        if total == 0:
            _msg = "No expected output was passed to ModuleIO"
            raise Exception(_msg)

        faulty_per = (1 - (present / total)) * 100

        # added this method here to avoid modifying all calls in the
        # modules' run method. We can think about restructure this part
        # in the future.
        self.remove_missing()

        return faulty_per

    def remove_missing(self) -> None:
        """Remove missing structure from `output`."""
        # can't modify a list/dictionary within a loop
        idxs: list[int] = []
        for idx, element in enumerate(self.output):
            if isinstance(element, dict):
                to_pop = []
                for key2 in element:
                    if not element[key2].is_present():
                        to_pop.append(key2)
                for pop_me in to_pop:
                    element.pop(pop_me)
            else:
                if not element.is_present():
                    idxs.append(idx)

        self.output = [
            value for i, value in enumerate(self.output)
            if i not in idxs
            ]

    def __repr__(self) -> str:
        return f"Input: {self.input}{linesep}Output: {self.output}"

    def load_from_input_molecules(
            self,
            input_molecules_dir: Path,
            ) -> None:
        """Load first molecules at the stat of the workflow.

        Parameters
        ----------
        input_molecules_dir : Path
            Directory where the input molecules are stored.
        """
        # Gather all input molecules
        input_molecules = list(input_molecules_dir.glob('*.pdb'))
        assert input_molecules != [], \
            f"No molecules could be found in `{input_molecules_dir}`"
        # Sort them by creation date (which is also input order)
        input_molecules.sort(key=getmtime)  # FIXME: getctime ?
        # Set input attribute
        self.input = input_molecules

        # Set parsing variables
        molecules_list: list[dict[int, PDBFile]] = [
            Molecule(input_file).pdb_files
            for input_file in self.input
            ]
        # And fake them to be the output of the previous io
        self.output = molecules_list
    

class Molecule:
    """
    Input molecule, usually a PDB file.

    Parameters
    ----------
    file_name : :external:py:class:`pathlib.Path`
        The path to the molecule file.

    segid : int, optional
        The ID of the segment. Defaults to ``None``.

    no_parent : boolean
        Whether to add the parent path ``..`` to the
        :py:attr:`haddock.libs.libstructure.Molecule.with_parent`.
        When set to true, the ``with_parent`` attribute returns the same
        as ``file_name``.
    """

    def __init__(
            self,
            pdb_file: Union[PDBFile, tuple[dict[int, PDBFile]], FilePath],
            ) -> None:
        self.input_file = pdb_file
        self._pdb_files: dict[int, PDBFile] = {}
        self.standardize_input_pdbfile()
    
    def standardize_input_pdbfile(self):
        if any([isinstance(self.input_file, ftype) for ftype in (str, Path)]):
            self.gen_pdb_object()
        else:
            self.pdb_files = self.input_file

    @property
    def count_models(self) -> int:
        self._nb_models = getattr(
            self,
            "_nb_models",
            1 if isinstance(self.pdb_files, PDBFile) \
            else len(self.pdb_files.keys()),
            )
        return self._nb_models

    @property
    def pdb_files(self) -> Union[dict[int, PDBFile], PDBFile]:
        return self._pdb_files

    @pdb_files.setter
    def pdb_files(self, value: Union[dict[int, PDBFile], PDBFile]) -> None:
        self._pdb_files = value
    
    def __len__(self) -> int:
        return self.count_models

    def __repr__(self) -> str:
        return f"Molecule {self.input_file}: {len(self)} models"

    def gen_pdb_object(self) -> None:
        # Create a Path object form input file
        pdb_filepath = self.input_file
        if not isinstance(pdb_filepath, Path):
            pdb_filepath = Path(pdb_filepath)
        # Obtain origin directory
        input_molecules_dir = pdb_filepath.parent
        # Eventually split models (they come back sorted by order in the file)
        splited_models = split_ensemble(
            pdb_filepath,
            dest=input_molecules_dir,
            )
        # get the MD5 hash of each model
        md5_dic = self.get_md5(pdb_filepath)
        origin_names = self.get_ensemble_origin(pdb_filepath)
        # Initiate holding variable
        pdb_files: dict[int, PDBFile] = {}
        # Loop over conformers of this ensemble
        for j, model in enumerate(splited_models):
            processed_model = model
            model_name = model.stem
            # Search of md5 information
            md5_hash = None
            try:
                model_id = int(model_name.split("_")[-1])
            except ValueError:
                model_id = 0
            if model_id in md5_dic:
                md5_hash = md5_dic[model_id]
            # Check if origin or md5 is available
            if md5_hash or model_id in origin_names.keys():
                # Select prefix
                if md5_hash:  # Prioritize the md5 hash
                    prefix_name = md5_hash
                else:
                    prefix_name = origin_names[model_id]
                # Build new filename
                model_new_name = f"{prefix_name}_from_{model_name}"
                # Rename file
                processed_model = model.rename(
                    Path(
                        input_molecules_dir,
                        f"{model_new_name}.pdb",
                        )
                    )
            # Create a PDBFile object
            pdbfile = PDBFile(
                processed_model,
                md5=md5_hash,
                )
            # Modify relative path attribute
            pdbfile.rel_path = Path(
                "..",
                input_molecules_dir,
                pdbfile.file_name
                )
            # Set origin name
            pdbfile.ori_name = pdb_filepath
            # Hold this guy
            pdb_files[j] = pdbfile
        # Set attribute
        self.pdb_files = pdb_files
    
    @staticmethod
    def get_md5(ensemble_f: FilePath) -> dict[int, str]:
        """Get MD5 hash of a multi-model PDB file."""
        md5_dic: dict[int, str] = {}
        text = Path(ensemble_f).read_text()
        lines = text.split(linesep)
        REMARK_lines = (line for line in lines if line.startswith("REMARK"))
        remd5 = re.compile(r"^[a-f0-9]{32}$")
        for line in REMARK_lines:
            parts = line.strip().split()

            try:
                idx = parts.index("MODEL")
            except ValueError:  # MODEL not in parts, this line can be ignored
                continue

            # check if there's a md5 hash in line
            for part in parts:
                group = remd5.fullmatch(part)
                if group:
                    # the model num comes after the MODEL
                    model_num = int(parts[idx + 1])
                    md5_dic[model_num] = group.string  # md5 hash
                    break

        return md5_dic
    
    @staticmethod
    def get_ensemble_origin(ensemble_f: FilePath) -> dict[int, str]:
        """Try to find origin for each model in ensemble.

        Parameters
        ----------
        ensemble_f : FilePath
            Path to a pdb file containing an ensemble.

        Returns
        -------
        origin_dic : dict[int, str]
            Dictionary holding as keys the modelID and values its origin.
        """
        origin_dic: dict[int, str] = {}
        text = Path(ensemble_f).read_text()
        lines = text.split(linesep)
        REMARK_lines = (line for line in lines if line.startswith("REMARK"))
        # Compile regex to parse filepath
        # https://regex101.com/r/fH0J6a/1
        re_origin = re.compile(
            r"REMARK\s+\d*\s+MODEL\s+(\d+)\s+(FROM|from|From)\s+[\./]{0,2}(([\w_\.-]+[/]?)+)\.?"  # noqa : E501
            )
        for line in REMARK_lines:
            if (match := re_origin.search(line)):
                model_num = int(match.group(1).strip())
                original_path = match.group(4).strip()
                original_name = Path(original_path).stem
                origin_dic[model_num] = original_name
        return origin_dic


def make_molecules(paths: Iterable[Path], **kwargs: Any) -> list[Molecule]:
    """Get input molecules from the data stream."""
    return list(map(partial(Molecule, **kwargs), paths))


PDBPath = Union[PDBFile, Path]

PDBPathT = TypeVar("PDBPathT", bound=Union[PDBFile, Path])
"""
Generic type variable for PDBFile or Path.

If the first annotated variable is PDBFile,
the second annotated variable will be PDBFile instead of Path,vice versa.
"""
